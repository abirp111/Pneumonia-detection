





!pip install numpy opencv-python tensorflow tensorflow-gpu==2.10.0 matplotlib scikit-learn seaborn





#Importing Tensorflow library
import tensorflow as tf


# Preventing Out of Memory error for the GPU
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)





#Importing some basic libraries for preparation & computation of the dataset
import numpy as np
import os
import cv2
from matplotlib import pyplot as plt


#Building the dataset pipeline
dataset = tf.keras.utils.image_dataset_from_directory('dataset', batch_size=32, image_size=(256, 256))


#Accessing dataset pipeline as a loop by converting as Numpy iterator
data_itr = dataset.as_numpy_iterator()
#Accessing single batch from dataset pipeline
#Grab another batch | A batch contains images and labels
selected_batch = data_itr.next()


fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(selected_batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(selected_batch[1][idx])





#Scaling Dataset
dataset = dataset.map(lambda x,y: (x/255, y)) #Going through images transformation to make the data access process faster by reducing size. x is images, y is labels


#Splitting Dataset to train, val and test
train_dataset_size = int(len(dataset)*.7)
val_dataset_size = int(len(dataset)*.2)
test_dataset_size = int(len(dataset)*.1)

#Preping and assigning train, val, test data to seperate instances
train = dataset.take(train_dataset_size)
val = dataset.skip(train_dataset_size).take(val_dataset_size)
test = dataset.skip(train_dataset_size + val_dataset_size).take(test_dataset_size)





from tensorflow.keras.models import Sequential #Sequential groups a linear stack of layers into a Model which is from Keras library used for 1 single input and 1 single output model building
from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras import regularizers


model = Sequential()


#Convolutional layer 1
#MobileNetV3Small applies 16 filters
model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same', kernel_regularizer='l2', input_shape=(256,256,3))) #With 16 filters, each filter got 3x3 pixel shape and it moves as 1 pixel
model.add(BatchNormalization())
model.add(MaxPooling2D())
#Convolutional layer 2
model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same', kernel_regularizer='l2'))
model.add(MaxPooling2D())
#Convolutional layer 3
model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same', kernel_regularizer='l2'))
model.add(MaxPooling2D())

#Flattening the model to one dimetional condensed layer
model.add(Flatten())
model.add(Dropout(0.3))

#Fully connected layers
model.add(Dense(256, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

#Compiling the model with Adam optimizer
#Specifing loss for binary classification problem
#Applying Accuracy matrix to track accuracy
model.compile('adam', metrics=['accuracy'], loss=tf.losses.BinaryCrossentropy())
model.summary()





#Setting up log
callback = tf.keras.callbacks.TensorBoard(log_dir='logs')
#Start training 400 times or epochs
history = model.fit(train, epochs=5, validation_data=val, callbacks=[callback])





fig = plt.figure()
plt.plot(history.history['loss'], label='loss', color='red')
plt.plot(history.history['val_loss'], label='val_loss', color='yellow')
fig.suptitle('Loss', fontsize=18)
plt.legend(loc="upper right")
plt.savefig('loss.jpg')
plt.show()


fig = plt.figure()
plt.plot(history.history['accuracy'], label='accuracy', color='green')
plt.plot(history.history['val_accuracy'], label='val_accuracy', color='purple')
fig.suptitle('Accuracy', fontsize=18)
plt.legend(loc="lower right")
plt.savefig('accuracy.jpg')
plt.show()





from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy, TruePositives, TrueNegatives, FalsePositives, FalseNegatives
from sklearn.metrics import confusion_matrix
import seaborn as sns


# Calculating Precision, Recall, Binary Accuracy & Confusion Matrix
pre = Precision()
re = Recall()
acc = BinaryAccuracy()

arr_y = np.empty(0)
arr_y_pred = np.empty(0)

for selected_batch in test.as_numpy_iterator():
    x, y = selected_batch
    y_pred = model.predict(x)
    
    arr_y = np.append(arr_y, y)
    arr_y_pred = np.append(arr_y_pred, y_pred)
    
    pre.update_state(y, y_pred)
    re.update_state(y, y_pred)
    acc.update_state(y, y_pred)


# Calculating F1-Score metrics
f1_score = 2 * (pre.result().numpy() * re.result().numpy()) / (pre.result().numpy()+re.result().numpy())
print("Precision:", pre.result().numpy(), ", Recall:", re.result().numpy(), ", Binary Accuracy: ", acc.result().numpy(), ", F1-Score: ", f1_score)


# Plotting the above metrics
labels = [f'Precision: {round(pre.result().numpy()*100, 2)}%', f'Recall: {round(re.result().numpy()*100, 2)}%', f'Binary Acc.: {round(acc.result().numpy()*100, 2)}%', f'F1-Score: {round(f1_score*100, 2)}%']
values = [pre.result().numpy()*100, re.result().numpy()*100, acc.result().numpy()*100, f1_score*100]
x = np.arange(len(labels))
width = 0.35

fig, ax = plt.subplots()
rects = ax.bar(x-width/2, values, width, label="Metrics")
ax.set_xticks(x, labels)
plt.title("Metrics: Precision, Recall, Binary Accuracy & F1-Score")
plt.savefig('metrics.jpg')
plt.show()


new_y_pred = np.empty(0)

# Going through the predictions and since the Confusion Matrix function cannot take binary and continuous values together, so setting up the threshold to 0.5
# If the predicted value is greater than or equal to 0.5 then it would result as Pnumonia which is class 1, otherwise Normal which is class 0 
for pred_val in arr_y_pred:
    if pred_val >= 0.5:
        new_y_pred = np.append(new_y_pred, 1)
    else:
        new_y_pred = np.append(new_y_pred, 0)


# Confusion Matrix | 0 = Normal, 1 = Pneumonia
cm = confusion_matrix(y_true=arr_y, y_pred=new_y_pred)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title("Confusion Matrix (0-Normal, 1-Pneumonia)")
plt.savefig('confusion_matrix.jpg')
plt.show()





import webbrowser
import winsound


img = cv2.imread(os.path.join('2.jpg'))
plt.imshow(img)
plt.show()


resized_img = tf.image.resize(img, (256,256))
plt.imshow(resized_img.numpy().astype(int))
plt.show()


y_pred = model.predict(np.expand_dims(resized_img/255, 0))


print('Predicted value:', y_pred[0][0])
if y_pred > 0.5: 
    print('WARNING! Pneumonia detected!!!')
    url = "https://www.mayoclinic.org/diseases-conditions/pneumonia/diagnosis-treatment/drc-20354210#ul_0b6cac6e-7ca6-4870-b363-d8ee70a56c83"
    webbrowser.open(url, new=0, autoraise=True)
    duration = 1000  # milliseconds
    freq = 440  # Hz
    winsound.Beep(freq, duration)
else:
    print('This X-Ray is Normal.')





from tensorflow.keras.models import load_model


model.save(os.path.join('output','pneumonia_detector.h5'))


new_model = load_model(os.path.join('output','pneumonia_detector.h5'))


new_model.predict(np.expand_dims(resized_img/255, 0))
